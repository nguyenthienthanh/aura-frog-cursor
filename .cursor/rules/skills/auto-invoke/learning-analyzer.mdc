---
description: "Analyze collected learning data to identify success patterns, failure patterns, optimization opportunities, and agent performance. Trigger: /learn:analyze command."
globs: []
alwaysApply: false
---

# Learning Analyzer

**Type:** Analysis
**Trigger:** `/learn:analyze`, on-demand
**Auto-invoke:** No (manual trigger only)

## Purpose

Analyze collected learning data from Supabase to identify:
- Success patterns (what's working well)
- Failure patterns (common issues)
- Optimization opportunities (efficiency improvements)
- Agent performance trends

## Usage

```bash
/learn:analyze                      # Full analysis
/learn:analyze --period 30d         # Last 30 days only
/learn:analyze --focus agents       # Focus on agent performance
/learn:analyze --focus workflows    # Focus on workflow patterns
/learn:analyze --focus feedback     # Focus on user feedback
```

## Analysis Process

### 1. Data Collection

Query Supabase views:
- `v_agent_success_rates` - Agent performance by task type
- `v_common_patterns` - Identified patterns
- `v_improvement_suggestions` - Actionable suggestions
- `v_workflow_trends` - Weekly workflow trends
- `v_feedback_summary` - Feedback statistics

### 2. Pattern Recognition

Use AI to identify patterns:

```
Given the learning data below, identify:
1. Top 3 success patterns (what's consistently working)
2. Top 3 failure patterns (recurring issues)
3. Top 3 optimization opportunities (efficiency gains)
4. Agent recommendations (which agents for which tasks)
```

### 3. Generate Insights

Output format:

```markdown
## Learning Analysis Report
Generated: {timestamp}
Period: {start_date} to {end_date}

### Success Patterns
1. **Pattern**: {description}
   - Frequency: {count} occurrences
   - Confidence: {percentage}%
   - Evidence: {examples}

### Failure Patterns
1. **Pattern**: {description}
   - Impact: {severity}
   - Root Cause: {analysis}
   - Suggested Fix: {recommendation}

### Agent Recommendations
| Task Type | Recommended Agent | Success Rate |
|-----------|-------------------|--------------|
| {type}    | {agent}           | {rate}%      |
```

## Environment Requirements

```bash
AF_LEARNING_ENABLED=true
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SECRET_KEY=your-service-role-key
```

## Query Templates

### Agent Success Rates

```sql
SELECT * FROM v_agent_success_rates
WHERE total_tasks >= 5
ORDER BY success_rate DESC;
```

### Recent Patterns

```sql
SELECT * FROM v_common_patterns
WHERE confidence >= 0.5
ORDER BY frequency DESC
LIMIT 20;
```

### Improvement Suggestions

```sql
SELECT * FROM v_improvement_suggestions
ORDER BY confidence DESC;
```

## Integration with Self-Improve

After analysis, suggested improvements can be:
1. Reviewed manually via `/learn:apply`
2. Applied automatically via `/learn:apply --auto` (high confidence only)

## Example Output

```markdown
## Learning Analysis Report
Generated: 2026-01-07
Period: Last 30 days

### Key Metrics
- Workflows analyzed: 47
- Success rate: 78.7%
- Feedback items: 23
- Patterns identified: 12

### Success Patterns

1. **TDD workflow with Next.js projects**
   - Frequency: 15 occurrences
   - Confidence: 89%
   - Evidence: 95% test pass rate when full TDD used

2. **react-expert for component tasks**
   - Frequency: 28 occurrences
   - Confidence: 92%
   - Evidence: 96% success rate

### Failure Patterns

1. **Phase 5a timeout on large test suites**
   - Frequency: 8 occurrences
   - Impact: High (workflow stall)
   - Root Cause: Test generation exceeds timeout
   - Suggested Fix: Add test batching

### Agent Recommendations

| Task Type | Agent | Success Rate |
|-----------|-------|--------------|
| React UI | react-expert | 96% |
| API routes | nodejs-expert | 88% |
```

---

**Version:** 1.10.0
